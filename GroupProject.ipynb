{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39c3c35",
   "metadata": {},
   "source": [
    "### Air Quality Monitor and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7954d",
   "metadata": {},
   "source": [
    "1. Dataset\n",
    "\n",
    "Name: Air Quality Data - Updated Hourly\n",
    "This website provides global air quality data updated hourly on the pollutants of PM2.5, PM10, O3 (Ozone), NO2 (Nitrogen dioxide), SO2 (Sulfur dioxide), CO (Carbon monoxide)\n",
    "\n",
    "2. Research Questions\n",
    "\n",
    "How do hourly air pollution patterns (PM₂.₅, NO₂, O₃) vary across major cities, and when do cities experience statistically significant spikes relative to their typical baseline?\n",
    "We will focus on 6 major cities that allows us to have strong diversity for meaningful comparison across the globe\n",
    "NYC\n",
    "London\n",
    "Hong Kong\n",
    "Delhi\n",
    "São Paulo\n",
    "Tokyo\n",
    "\n",
    "3. Notebook Link\n",
    "\n",
    "4. Target Visualization\n",
    "To be updated\n",
    "5. Known Unknowns\n",
    "\n",
    "Known:\n",
    "Timestamped hourly pollutant readings for (PM2.5, NO2, O3), which allows us to conduct pattern analysis and produce day-of week comparisons, spike detection, and form rolling averages\n",
    "All pollutants share the same measurement of µg/m³\n",
    "Geographic coordinates, which allows us to monitor stations for cross-city comparisons, spatial clustering, and mapping in Streamlit\n",
    "Clearly specified pollutant types allows us to compare traffic-related and climate-related patterns\n",
    "Real-time data enables a live dashboard for trend and monitoring applications in our application development\n",
    "\n",
    "Unknown:\n",
    "Data Quality may vary as OpenAQ aggregates from multiple providers, such as government monitors, low-cost sensors, and private contributors. We are unsure if all monitors are calibrated equally, which may reflect monitoring quality difference when using the data for cross-city comparisons\n",
    "Station placement bias because the stations are not randomly distributed, as they may be placed near highways, industrial zones, residential areas, etc. that may not represent the entire city fairly. This affects spike interpretation and baseline calculation. We may need to consider pulling data from multiple locations within a city with city-level aggregates, using median values and standard deviations to make the cities more comparable\n",
    "The definition of spike needs to be constructed\n",
    "No direct causal variables of traffic counts, weather (temperature and wind), policy changes, industrial output, wildfire data. We may need another set of data(s) to identify the direct causes\n",
    "\n",
    "6. Anticipated Challenges\n",
    "\n",
    "Making sure the time stamps are consistent across the data and making sure the time zones are correct\n",
    "Computing the baseline and spikes correctly, by using city-level hourly aggregation, rolling baseline, and rolling variability estimates. This requires computing the z-score or robust z-score\n",
    "Need to code to log data pull times and timestamps of a specific time to produce live data on our application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971d16a",
   "metadata": {},
   "source": [
    "## To be Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e43079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC locations returned: 60\n",
      "pm25: chosen location_id=384, sensor_id=673, hours returned=200\n",
      "no2: chosen location_id=853, sensor_id=1523, hours returned=200\n",
      "o3: chosen location_id=384, sensor_id=671, hours returned=200\n",
      "raw df shape: (600, 7)\n",
      "sample hour record (for debugging): {'value': 2.4, 'flagInfo': {'hasFlags': False}, 'parameter': {'id': 2, 'name': 'pm25', 'units': 'µg/m³', 'displayName': None}, 'period': {'label': '1hour', 'interval': '01:00:00', 'datetimeFrom': {'utc': '2016-03-12T08:00:00Z', 'local': '2016-03-12T03:00:00-05:00'}, 'datetimeTo': {'utc': '2016-03-12T09:00:00Z', 'local': '2016-03-12T04:00:00-05:00'}}, 'coordinates': None, 'summary': {'min': 2.4, 'q02': 2.4, 'q25': 2.4, 'median': 2.4, 'q75': 2.4, 'q98': 2.4, 'max': 2.4, 'avg': 2.4, 'sd': None}, 'coverage': {'expectedCount': 1, 'expectedInterval': '01:00:00', 'observedCount': 1, 'observedInterval': '01:00:00', 'percentComplete': 100.0, 'percentCoverage': 100.0, 'datetimeFrom': {'utc': '2016-03-12T08:00:00Z', 'local': '2016-03-12T03:00:00-05:00'}, 'datetimeTo': {'utc': '2016-03-12T09:00:00Z', 'local': '2016-03-12T04:00:00-05:00'}}}\n",
      "missing datetime rate: 0.0\n",
      "missing value rate: 0.0\n",
      "clean df shape: (600, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>parameter</th>\n",
       "      <th>location_id</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-03-31 18:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-03-31 19:00:00+00:00</td>\n",
       "      <td>0.011</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 02:00:00+00:00</td>\n",
       "      <td>0.010</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 03:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 04:00:00+00:00</td>\n",
       "      <td>0.004</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 05:00:00+00:00</td>\n",
       "      <td>0.003</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 06:00:00+00:00</td>\n",
       "      <td>0.003</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 07:00:00+00:00</td>\n",
       "      <td>0.004</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 08:00:00+00:00</td>\n",
       "      <td>0.004</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 09:00:00+00:00</td>\n",
       "      <td>0.007</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 10:00:00+00:00</td>\n",
       "      <td>0.012</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 11:00:00+00:00</td>\n",
       "      <td>0.016</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 12:00:00+00:00</td>\n",
       "      <td>0.019</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 13:00:00+00:00</td>\n",
       "      <td>0.015</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 14:00:00+00:00</td>\n",
       "      <td>0.012</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 15:00:00+00:00</td>\n",
       "      <td>0.011</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 16:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 17:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 18:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>NYC</td>\n",
       "      <td>no2</td>\n",
       "      <td>853</td>\n",
       "      <td>1523</td>\n",
       "      <td>2016-04-01 19:00:00+00:00</td>\n",
       "      <td>0.009</td>\n",
       "      <td>ppm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city parameter  location_id  sensor_id                  datetime  value  \\\n",
       "200  NYC       no2          853       1523 2016-03-31 18:00:00+00:00  0.009   \n",
       "201  NYC       no2          853       1523 2016-03-31 19:00:00+00:00  0.011   \n",
       "202  NYC       no2          853       1523 2016-04-01 02:00:00+00:00  0.010   \n",
       "203  NYC       no2          853       1523 2016-04-01 03:00:00+00:00  0.009   \n",
       "204  NYC       no2          853       1523 2016-04-01 04:00:00+00:00  0.004   \n",
       "205  NYC       no2          853       1523 2016-04-01 05:00:00+00:00  0.003   \n",
       "206  NYC       no2          853       1523 2016-04-01 06:00:00+00:00  0.003   \n",
       "207  NYC       no2          853       1523 2016-04-01 07:00:00+00:00  0.004   \n",
       "208  NYC       no2          853       1523 2016-04-01 08:00:00+00:00  0.004   \n",
       "209  NYC       no2          853       1523 2016-04-01 09:00:00+00:00  0.007   \n",
       "210  NYC       no2          853       1523 2016-04-01 10:00:00+00:00  0.012   \n",
       "211  NYC       no2          853       1523 2016-04-01 11:00:00+00:00  0.016   \n",
       "212  NYC       no2          853       1523 2016-04-01 12:00:00+00:00  0.019   \n",
       "213  NYC       no2          853       1523 2016-04-01 13:00:00+00:00  0.015   \n",
       "214  NYC       no2          853       1523 2016-04-01 14:00:00+00:00  0.012   \n",
       "215  NYC       no2          853       1523 2016-04-01 15:00:00+00:00  0.011   \n",
       "216  NYC       no2          853       1523 2016-04-01 16:00:00+00:00  0.009   \n",
       "217  NYC       no2          853       1523 2016-04-01 17:00:00+00:00  0.009   \n",
       "218  NYC       no2          853       1523 2016-04-01 18:00:00+00:00  0.009   \n",
       "219  NYC       no2          853       1523 2016-04-01 19:00:00+00:00  0.009   \n",
       "\n",
       "    unit  \n",
       "200  ppm  \n",
       "201  ppm  \n",
       "202  ppm  \n",
       "203  ppm  \n",
       "204  ppm  \n",
       "205  ppm  \n",
       "206  ppm  \n",
       "207  ppm  \n",
       "208  ppm  \n",
       "209  ppm  \n",
       "210  ppm  \n",
       "211  ppm  \n",
       "212  ppm  \n",
       "213  ppm  \n",
       "214  ppm  \n",
       "215  ppm  \n",
       "216  ppm  \n",
       "217  ppm  \n",
       "218  ppm  \n",
       "219  ppm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, time, requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import re\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Config\n",
    "# ----------------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAQ_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Missing OPENAQ_API_KEY (check .env)\")\n",
    "\n",
    "HEADERS = {\"X-API-Key\": API_KEY}\n",
    "BASE = \"https://api.openaq.org/v3\"\n",
    "\n",
    "CITY = \"NYC\"\n",
    "BBOX = \"-74.30,40.50,-73.70,40.92\"\n",
    "PARAMETERS = [\"pm25\", \"no2\", \"o3\"]\n",
    "\n",
    "now = datetime.now(timezone.utc)\n",
    "start = now - timedelta(hours=24)   # 需要更保险可改 days=7\n",
    "DATE_FROM = start.isoformat(timespec=\"seconds\")\n",
    "DATE_TO = now.isoformat(timespec=\"seconds\")\n",
    "\n",
    "LOC_LIMIT = 60\n",
    "SENSOR_LIMIT = 200\n",
    "HOURS_LIMIT = 200\n",
    "SLEEP_S = 0.12\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) HTTP helper\n",
    "# ----------------------------\n",
    "def get_json(url, params=None):\n",
    "    r = requests.get(url, headers=HEADERS, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    time.sleep(SLEEP_S)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def normalize_param(p):\n",
    "    if p is None:\n",
    "        return \"\"\n",
    "    if isinstance(p, str):\n",
    "        return p.lower()\n",
    "    if isinstance(p, dict):\n",
    "        return str(p.get(\"name\") or p.get(\"code\") or \"\").lower()\n",
    "    return str(p).lower()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Recursive leaf collection (key part)\n",
    "# ----------------------------\n",
    "ISO_HINT = re.compile(r\"\\d{4}-\\d{2}-\\d{2}T\")  # quick ISO8601 hint\n",
    "\n",
    "def collect_leaves(obj, path=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively collect leaf values with their paths.\n",
    "    Returns list of tuples: (path, value)\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            out.extend(collect_leaves(v, f\"{path}.{k}\" if path else str(k)))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, v in enumerate(obj):\n",
    "            out.extend(collect_leaves(v, f\"{path}[{i}]\"))\n",
    "    else:\n",
    "        out.append((path, obj))\n",
    "    return out\n",
    "\n",
    "\n",
    "def pick_datetime_from_record(rec):\n",
    "    \"\"\"\n",
    "    Try common paths first, then fallback to scanning all string leaves that look like ISO datetime.\n",
    "    \"\"\"\n",
    "    # common candidates (your v3 may differ)\n",
    "    candidates = [\n",
    "        rec.get(\"datetime\"),\n",
    "        (rec.get(\"datetime\") or {}).get(\"utc\") if isinstance(rec.get(\"datetime\"), dict) else None,\n",
    "        (rec.get(\"date\") or {}).get(\"utc\") if isinstance(rec.get(\"date\"), dict) else None,\n",
    "        (rec.get(\"period\") or {}).get(\"datetimeFrom\") if isinstance(rec.get(\"period\"), dict) else None,\n",
    "        (rec.get(\"period\") or {}).get(\"datetimeTo\") if isinstance(rec.get(\"period\"), dict) else None,\n",
    "        rec.get(\"timestamp\"),\n",
    "        rec.get(\"time\"),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if isinstance(c, str) and ISO_HINT.search(c):\n",
    "            dt = pd.to_datetime(c, errors=\"coerce\", utc=True)\n",
    "            if not pd.isna(dt):\n",
    "                return c\n",
    "\n",
    "    # fallback: scan all leaves\n",
    "    leaves = collect_leaves(rec)\n",
    "    for p, v in leaves:\n",
    "        if isinstance(v, str) and ISO_HINT.search(v):\n",
    "            dt = pd.to_datetime(v, errors=\"coerce\", utc=True)\n",
    "            if not pd.isna(dt):\n",
    "                return v\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def pick_value_from_record(rec):\n",
    "    \"\"\"\n",
    "    Try common paths first, then fallback to first numeric leaf.\n",
    "    \"\"\"\n",
    "    # common candidates\n",
    "    candidates = [\n",
    "        rec.get(\"value\"),\n",
    "        rec.get(\"avg\"),\n",
    "        rec.get(\"mean\"),\n",
    "        rec.get(\"median\"),\n",
    "        rec.get(\"average\"),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if isinstance(c, (int, float)):\n",
    "            return c\n",
    "        if isinstance(c, dict):\n",
    "            for k in [\"value\", \"avg\", \"mean\", \"median\"]:\n",
    "                if isinstance(c.get(k), (int, float)):\n",
    "                    return c.get(k)\n",
    "\n",
    "    # fallback: scan numeric leaves\n",
    "    leaves = collect_leaves(rec)\n",
    "    for p, v in leaves:\n",
    "        if isinstance(v, (int, float)):\n",
    "            return v\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def pick_unit_from_record(rec):\n",
    "    u = rec.get(\"unit\")\n",
    "    if isinstance(u, str):\n",
    "        return u\n",
    "    p = rec.get(\"parameter\")\n",
    "    if isinstance(p, dict) and isinstance(p.get(\"unit\"), str):\n",
    "        return p.get(\"unit\")\n",
    "\n",
    "    # fallback: scan for likely unit strings (optional)\n",
    "    leaves = collect_leaves(rec)\n",
    "    for path, v in leaves:\n",
    "        if isinstance(v, str) and v in [\"µg/m³\", \"ug/m3\", \"ppm\", \"ppb\"]:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) OpenAQ data functions\n",
    "# ----------------------------\n",
    "def get_locations_by_bbox(bbox, limit=60):\n",
    "    data = get_json(f\"{BASE}/locations\", params={\"bbox\": bbox, \"limit\": limit, \"page\": 1})\n",
    "    return data.get(\"results\", [])\n",
    "\n",
    "\n",
    "def get_sensors_for_location(location_id, limit=200):\n",
    "    data = get_json(f\"{BASE}/locations/{location_id}/sensors\", params={\"limit\": limit, \"page\": 1})\n",
    "    return data.get(\"results\", [])\n",
    "\n",
    "\n",
    "def get_sensor_hours(sensor_id, date_from, date_to, limit=200):\n",
    "    data = get_json(\n",
    "        f\"{BASE}/sensors/{sensor_id}/hours\",\n",
    "        params={\"date_from\": date_from, \"date_to\": date_to, \"limit\": limit, \"page\": 1}\n",
    "    )\n",
    "    return data.get(\"results\", [])\n",
    "\n",
    "\n",
    "def find_working_sensor_for_param(locs, param):\n",
    "    \"\"\"\n",
    "    Find first (location_id, sensor_id, hours_records) that:\n",
    "    - has matching parameter sensor\n",
    "    - hours endpoint returns non-empty list\n",
    "    \"\"\"\n",
    "    target = param.lower()\n",
    "    for loc in locs:\n",
    "        loc_id = loc[\"id\"]\n",
    "        sensors = get_sensors_for_location(loc_id, limit=SENSOR_LIMIT)\n",
    "        matched = [s for s in sensors if normalize_param(s.get(\"parameter\")) == target]\n",
    "        for s in matched:\n",
    "            sid = s[\"id\"]\n",
    "            hours = get_sensor_hours(sid, DATE_FROM, DATE_TO, limit=HOURS_LIMIT)\n",
    "            if hours:\n",
    "                return loc_id, sid, hours\n",
    "    return None, None, []\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Main: build sample df\n",
    "# ----------------------------\n",
    "locs = get_locations_by_bbox(BBOX, limit=LOC_LIMIT)\n",
    "print(f\"{CITY} locations returned:\", len(locs))\n",
    "if not locs:\n",
    "    raise RuntimeError(\"No locations in bbox. Try enlarging bbox.\")\n",
    "\n",
    "rows = []\n",
    "debug_first_record = None\n",
    "\n",
    "for param in PARAMETERS:\n",
    "    loc_id, sensor_id, hours = find_working_sensor_for_param(locs, param)\n",
    "    if not sensor_id:\n",
    "        print(f\"[WARN] No working sensor for {param}. Try wider window (days=7).\")\n",
    "        continue\n",
    "\n",
    "    print(f\"{param}: chosen location_id={loc_id}, sensor_id={sensor_id}, hours returned={len(hours)}\")\n",
    "\n",
    "    if hours and debug_first_record is None:\n",
    "        debug_first_record = hours[0]\n",
    "\n",
    "    for rec in hours:\n",
    "        dt = pick_datetime_from_record(rec)\n",
    "        val = pick_value_from_record(rec)\n",
    "        unit = pick_unit_from_record(rec)\n",
    "\n",
    "        rows.append({\n",
    "            \"city\": CITY,\n",
    "            \"parameter\": param,\n",
    "            \"location_id\": loc_id,\n",
    "            \"sensor_id\": sensor_id,\n",
    "            \"datetime\": dt,\n",
    "            \"value\": val,\n",
    "            \"unit\": unit\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"raw df shape:\", df.shape)\n",
    "\n",
    "# quick debug: show one raw hour record structure if cleaning still fails\n",
    "if debug_first_record is not None:\n",
    "    print(\"sample hour record (for debugging):\", debug_first_record)\n",
    "\n",
    "if df.empty:\n",
    "    print(\"No rows collected at all.\")\n",
    "else:\n",
    "    # parse + clean (now should keep rows)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"], errors=\"coerce\", utc=True)\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "    # print missing rates before dropping\n",
    "    print(\"missing datetime rate:\", df[\"datetime\"].isna().mean())\n",
    "    print(\"missing value rate:\", df[\"value\"].isna().mean())\n",
    "\n",
    "    df_clean = df.dropna(subset=[\"datetime\", \"value\"]).sort_values([\"parameter\", \"datetime\"])\n",
    "    print(\"clean df shape:\", df_clean.shape)\n",
    "    display(df_clean.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
